{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install langchain_groq\n",
        "!pip install langchain_community\n",
        "!pip install langgraph\n",
        "!pip install arxiv\n",
        "!pip install tavily_tool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14gsDS4CJuSt",
        "outputId": "a3fa2698-49a5-49dc-ad27-13af7247ab88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.21)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.47)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.18)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.47 in /usr/local/lib/python3.11/dist-packages (from langchain_groq) (0.3.47)\n",
            "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
            "  Downloading groq-0.20.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.47->langchain_groq) (0.3.18)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.47->langchain_groq) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.47->langchain_groq) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.47->langchain_groq) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.47->langchain_groq) (24.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.47->langchain_groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (2.3.0)\n",
            "Downloading langchain_groq-0.3.1-py3-none-any.whl (15 kB)\n",
            "Downloading groq-0.20.0-py3-none-any.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain_groq\n",
            "Successfully installed groq-0.20.0 langchain_groq-0.3.1\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.47)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.21 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.21)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.18)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.21->langchain_community) (0.3.7)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.21->langchain_community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain_community) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.20-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.20 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.3.20-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.47)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.23-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.6-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.59-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xxhash<4.0.0,>=3.5.0 (from langgraph)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (0.3.18)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (2.10.6)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
            "  Downloading ormsgpack-1.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.3.20-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.23-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.1.6-py3-none-any.whl (25 kB)\n",
            "Downloading langgraph_sdk-0.1.59-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.3.20 langgraph-checkpoint-2.0.23 langgraph-prebuilt-0.1.6 langgraph-sdk-0.1.59 ormsgpack-1.9.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "groq_api_key=userdata.get('GROQ_API_KEY')\n",
        "tavily_api_key=userdata.get('TAVILY_API_KEY')"
      ],
      "metadata": {
        "id": "qO7kllqDJubV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmwHr-qoJkIx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import ast\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_core.language_models import BaseLanguageModel\n",
        "from langchain_community.tools import ArxivQueryRun, TavilySearchResults\n",
        "from langchain_core.tools import BaseTool\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "class ResearchTask(BaseModel):\n",
        "    \"\"\"Represents a single research task\"\"\"\n",
        "    task_id: str\n",
        "    description: str\n",
        "    priority: int = Field(ge=1, le=5)\n",
        "    status: str = \"pending\"\n",
        "    result: Optional[str] = None\n",
        "    validation_notes: Optional[str] = None\n",
        "    tool_results: Dict[str, str] = {}\n",
        "    llm_prompt: Optional[str] = None\n",
        "\n",
        "class ResearchState(BaseModel):\n",
        "    \"\"\"Represents the state of the research process\"\"\"\n",
        "    query: str\n",
        "    tasks: List[ResearchTask] = Field(default_factory=list)\n",
        "    completed_tasks: List[ResearchTask] = Field(default_factory=list)\n",
        "    current_results: Dict[str, Any] = Field(default_factory=dict)\n",
        "    final_answer: Optional[str] = None\n",
        "    messages: List[Dict[str, Any]] = Field(default_factory=list)\n",
        "\n",
        "class TaskPlan(BaseModel):\n",
        "    \"\"\"Output schema for the planner component\"\"\"\n",
        "    tasks: List[ResearchTask] = Field(description=\"List of research tasks to accomplish\")\n",
        "    reasoning: str = Field(description=\"Explanation of how these tasks will help answer the query\")\n",
        "\n",
        "class ResearchLangGraphAgent:\n",
        "    def __init__(self,\n",
        "                 llm: Optional[BaseLanguageModel] = None\n",
        "                 ):\n",
        "        \"\"\"\n",
        "        Initialize the Research Agent with LangGraph\n",
        "\n",
        "        Args:\n",
        "            llm: Language model for generation (defaults to Groq)\n",
        "        \"\"\"\n",
        "        self.llm = ChatGroq(\n",
        "            model='llama3-70b-8192',\n",
        "            api_key=groq_api_key,\n",
        "            temperature=0.3\n",
        "        )\n",
        "\n",
        "        self.arxiv_tool = ArxivQueryRun()\n",
        "        self.tavily_tool = TavilySearchResults(tavily_api_key=tavily_api_key)\n",
        "\n",
        "        self.tools = [self.arxiv_tool, self.tavily_tool]\n",
        "\n",
        "    def select_tool(self, task_description: str) -> BaseTool:\n",
        "        \"\"\"\n",
        "        Select appropriate tool based on task description\n",
        "\n",
        "        Args:\n",
        "            task_description: Description of the research task\n",
        "\n",
        "        Returns:\n",
        "            Selected research tool\n",
        "        \"\"\"\n",
        "        task_lower = task_description.lower()\n",
        "        if \"literature review\" in task_lower or \"arxiv\" in task_lower:\n",
        "            return self.arxiv_tool\n",
        "        return self.tavily_tool\n",
        "\n",
        "    def simple_llm_call(self, prompt: str, system_prompt: Optional[str] = None) -> str:\n",
        "        \"\"\"Async LLM call for generating content\"\"\"\n",
        "        messages = []\n",
        "        if system_prompt:\n",
        "            messages.append(SystemMessage(content=system_prompt))\n",
        "\n",
        "        messages.append(HumanMessage(content=prompt))\n",
        "        response = self.llm.invoke(messages)\n",
        "        return response.content\n",
        "\n",
        "    def analyze_task_relationships_with_llm(self, tasks: List[ResearchTask]) -> Dict[int, List[str]]:\n",
        "        \"\"\"\n",
        "        Analyze relationships between tasks using an LLM to identify potential dependencies and prioritize tasks.\n",
        "\n",
        "        Args:\n",
        "            tasks: List of research tasks\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping priority levels to lists of task_ids\n",
        "        \"\"\"\n",
        "\n",
        "        task_descriptions = \"\\n\".join([f\"Task {task.task_id}: {task.description}\" for task in tasks])\n",
        "        prompt = (\n",
        "            f\"Here are some tasks:\\n\\n{task_descriptions}\\n\\n\"\n",
        "            \"Analyze the relationships between the tasks to identify dependencies. \"\n",
        "            \"Group tasks that can run in parallel into the same list. Order the groups such that tasks in a later group depend on tasks in earlier groups. \"\n",
        "            \"Return a dictionary where the key is the priority level (starting from 1), and the value is a list of task IDs that can run in parallel.\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            response = self.simple_llm_call(\n",
        "                prompt=prompt,\n",
        "                system_prompt=\"You are an expert task dependency analyzer. Provide a structured output of task priorities and parallel execution groups.\"\n",
        "            )\n",
        "\n",
        "            start = response.find(\"{\")\n",
        "            end = response.rfind(\"}\") + 1\n",
        "\n",
        "            if start != -1 and end != -1:\n",
        "                task_relationships_str = response[start:end]\n",
        "                task_relationships = ast.literal_eval(task_relationships_str)\n",
        "                if isinstance(task_relationships, dict):\n",
        "                    return task_relationships\n",
        "                else:\n",
        "                    raise ValueError(\"Extracted data is not in the expected dictionary format.\")\n",
        "            else:\n",
        "                raise ValueError(\"No dictionary found in the response.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Task relationship analysis failed: {e}\")\n",
        "            return {priority: [task.task_id for task in tasks if task.priority == priority]\n",
        "                    for priority in sorted(set(task.priority for task in tasks))}\n",
        "\n",
        "    async def generate_research_tasks(self, state: ResearchState) -> ResearchState:\n",
        "      \"\"\"\n",
        "      Generate research tasks based on the original query\n",
        "\n",
        "      Args:\n",
        "          state: Current research state\n",
        "\n",
        "      Returns:\n",
        "          Updated research state with tasks\n",
        "      \"\"\"\n",
        "      task_generation_prompt = f\"\"\"\n",
        "      Generate a list of research tasks for the following query:\n",
        "      \"{state.query}\"\n",
        "\n",
        "      Requirements:\n",
        "      - Create 3-4 specific, actionable research tasks\n",
        "      - Each task should contribute to answering the main query\n",
        "      - Provide a task ID, clear description, and initial priority\n",
        "\n",
        "      Output format:\n",
        "      {{\n",
        "          \"tasks\": [\n",
        "              {{\n",
        "                  \"task_id\": \"T1\",\n",
        "                  \"description\": \"...\",\n",
        "                  \"priority\": 1\n",
        "              }},\n",
        "              ...\n",
        "          ],\n",
        "          \"reasoning\": \"Explanation of task selection\"\n",
        "      }}\n",
        "      \"\"\"\n",
        "\n",
        "      response = self.llm.invoke([\n",
        "          SystemMessage(content=\"You are an expert research task generator. Always respond with a JSON block.\"),\n",
        "          HumanMessage(content=task_generation_prompt)\n",
        "      ])\n",
        "\n",
        "      try:\n",
        "          import re\n",
        "          json_match = re.search(r'```json?\\n(.*?)```', response.content, re.DOTALL)\n",
        "\n",
        "          if json_match:\n",
        "              json_str = json_match.group(1).strip()\n",
        "          else:\n",
        "              # If no code block, try to extract the entire JSON structure\n",
        "              json_match = re.search(r'\\{.*\\}', response.content, re.DOTALL)\n",
        "              if json_match:\n",
        "                  json_str = json_match.group(0).strip()\n",
        "              else:\n",
        "                  raise ValueError(\"No JSON structure found in the response\")\n",
        "\n",
        "          import json\n",
        "          parsed_json = json.loads(json_str)\n",
        "\n",
        "          task_plan = TaskPlan.model_validate(parsed_json)\n",
        "\n",
        "          state.tasks = task_plan.tasks\n",
        "          state.messages.append({\n",
        "              \"role\": \"system\",\n",
        "              \"content\": f\"Task Generation Reasoning: {task_plan.reasoning}\"\n",
        "          })\n",
        "\n",
        "          try:\n",
        "              task_relationships = self.analyze_task_relationships_with_llm(state.tasks)\n",
        "\n",
        "              for priority, task_ids in task_relationships.items():\n",
        "                  for task in state.tasks:\n",
        "                      if task.task_id in task_ids:\n",
        "                          task.priority = priority\n",
        "\n",
        "          except Exception as e:\n",
        "              print(f\"Task relationship analysis failed: {e}\")\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"Task generation error: {e}\")\n",
        "\n",
        "      return state\n",
        "\n",
        "    async def execute_research_task(self, state: ResearchState) -> ResearchState:\n",
        "        \"\"\"\n",
        "        Execute research tasks in parallel within priority groups\n",
        "\n",
        "        Args:\n",
        "            state: Current research state\n",
        "\n",
        "        Returns:\n",
        "            Updated research state with task results\n",
        "        \"\"\"\n",
        "        priority_groups = {}\n",
        "        for task in state.tasks.copy():\n",
        "            if task.priority not in priority_groups:\n",
        "                priority_groups[task.priority] = []\n",
        "            priority_groups[task.priority].append(task)\n",
        "\n",
        "        for priority in sorted(priority_groups.keys()):\n",
        "            current_tasks = priority_groups[priority]\n",
        "\n",
        "            task_results = await asyncio.gather(\n",
        "                *[self._execute_single_task(task) for task in current_tasks]\n",
        "            )\n",
        "\n",
        "            for completed_task in task_results:\n",
        "                state.completed_tasks.append(completed_task)\n",
        "                if completed_task in state.tasks:\n",
        "                    state.tasks.remove(completed_task)\n",
        "\n",
        "        return state\n",
        "\n",
        "    async def _execute_single_task(self, task: ResearchTask) -> ResearchTask:\n",
        "        \"\"\"\n",
        "        Execute a single research task\n",
        "\n",
        "        Args:\n",
        "            task: Research task to execute\n",
        "\n",
        "        Returns:\n",
        "            Updated research task with results\n",
        "        \"\"\"\n",
        "        try:\n",
        "            tool = self.select_tool(task.description)\n",
        "\n",
        "            tool_result = tool.run(task.description)\n",
        "\n",
        "            task.tool_results = {\"result\": str(tool_result)}\n",
        "\n",
        "            summary_prompt = f\"\"\"\n",
        "            Summarize the research findings for the task:\n",
        "            \"{task.description}\"\n",
        "\n",
        "            Research Data:\n",
        "            {tool_result}\n",
        "\n",
        "            Provide a concise summary with key insights and implications.\n",
        "            \"\"\"\n",
        "\n",
        "            summary = self.simple_llm_call(\n",
        "                prompt=summary_prompt,\n",
        "                system_prompt=\"You are an expert research summarizer.\"\n",
        "            )\n",
        "\n",
        "            task.result = summary\n",
        "            task.status = \"completed\"\n",
        "\n",
        "        except Exception as e:\n",
        "            task.status = \"failed\"\n",
        "            task.validation_notes = str(e)\n",
        "\n",
        "        return task\n",
        "\n",
        "    async def synthesize_final_report(self, state: ResearchState) -> ResearchState:\n",
        "        \"\"\"\n",
        "        Synthesize final research report from completed tasks\n",
        "\n",
        "        Args:\n",
        "            state: Current research state\n",
        "\n",
        "        Returns:\n",
        "            Updated research state with final report\n",
        "        \"\"\"\n",
        "        if not state.completed_tasks:\n",
        "            state.final_answer = \"No research findings available.\"\n",
        "            return state\n",
        "\n",
        "        synthesis_prompt = f\"\"\"\n",
        "        Original Query: {state.query}\n",
        "\n",
        "        Research Findings:\n",
        "        {chr(10).join([f\"Task {task.task_id}: {task.result}\" for task in state.completed_tasks])}\n",
        "\n",
        "        Synthesize these findings into a comprehensive, well-structured report.\n",
        "        Include key insights, potential implications, and a direct answer to the original query.\n",
        "        \"\"\"\n",
        "\n",
        "        final_report = self.simple_llm_call(\n",
        "            prompt=synthesis_prompt,\n",
        "            system_prompt=\"You are an expert research synthesizer.\"\n",
        "        )\n",
        "\n",
        "        state.final_answer = final_report\n",
        "        return state\n",
        "\n",
        "    async def validate_final_report(self, state: ResearchState) -> ResearchState:\n",
        "      \"\"\"\n",
        "      Validate the synthesized final report against the original query to check for hallucinations.\n",
        "      If validation fails, re-execute all tasks until a valid output is obtained.\n",
        "\n",
        "      Args:\n",
        "          state: Current research state\n",
        "\n",
        "      Returns:\n",
        "          Updated research state with validated final report\n",
        "      \"\"\"\n",
        "      validation_prompt = f\"\"\"\n",
        "      Given the original research query and the synthesized report, validate whether the report accurately answers the query.\n",
        "\n",
        "      Original Query: {state.query}\n",
        "\n",
        "      Synthesized Report:\n",
        "      {state.final_answer}\n",
        "\n",
        "      Validation Criteria:\n",
        "      - Ensure the report directly addresses the original query.\n",
        "      - Verify that key insights are well-supported by research findings.\n",
        "      - Identify and flag any hallucinations or unsupported claims.\n",
        "\n",
        "      Output format (JSON):\n",
        "      {{\n",
        "          \"valid\": true/false,\n",
        "          \"validation_notes\": \"...\"\n",
        "      }}\n",
        "      \"\"\"\n",
        "\n",
        "      response = self.simple_llm_call(\n",
        "          prompt=validation_prompt,\n",
        "          system_prompt=\"You are a research validator. Ensure factual accuracy and alignment with the original query. Always respond in JSON format.\"\n",
        "      )\n",
        "\n",
        "      import json\n",
        "      import re\n",
        "\n",
        "      try:\n",
        "          json_match = re.search(r'```json?\\n(.*?)```', response, re.DOTALL)\n",
        "\n",
        "          if json_match:\n",
        "              json_str = json_match.group(1).strip()\n",
        "          else:\n",
        "              json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
        "              if json_match:\n",
        "                  json_str = json_match.group(0).strip()\n",
        "              else:\n",
        "                  raise ValueError(\"No JSON structure found in the response\")\n",
        "\n",
        "          validation_result = json.loads(json_str)\n",
        "\n",
        "          if validation_result.get(\"valid\", False):\n",
        "              state.final_answer = state.final_answer\n",
        "              state.messages.append({\n",
        "                  \"role\": \"validator\",\n",
        "                  \"content\": f\"Validation Successful: {validation_result['validation_notes']}\"\n",
        "              })\n",
        "          else:\n",
        "              state.final_answer = None\n",
        "              state.messages.append({\n",
        "                  \"role\": \"validator\",\n",
        "                  \"content\": f\"Validation Failed: {validation_result['validation_notes']}. Re-executing tasks...\"\n",
        "              })\n",
        "\n",
        "              # Re-run task execution\n",
        "              state.tasks = state.completed_tasks.copy()\n",
        "              state.completed_tasks.clear()\n",
        "              state = await self.execute_research_task(state)\n",
        "              state = await self.synthesize_final_report(state)\n",
        "              state = await self.validate_final_report(state)  # Recursively validate again\n",
        "\n",
        "      except Exception as e:\n",
        "          state.messages.append({\n",
        "              \"role\": \"validator\",\n",
        "              \"content\": f\"Validation error: {str(e)}\"\n",
        "          })\n",
        "\n",
        "      return state\n",
        "\n",
        "    def create_research_workflow(self) -> StateGraph:\n",
        "        \"\"\"\n",
        "        Create LangGraph workflow for research\n",
        "\n",
        "        Returns:\n",
        "            Configured StateGraph\n",
        "        \"\"\"\n",
        "        workflow = StateGraph(ResearchState)\n",
        "\n",
        "        # Add nodes\n",
        "        workflow.add_node(\"generate_tasks\", self.generate_research_tasks)\n",
        "        workflow.add_node(\"execute_research\", self.execute_research_task)\n",
        "        workflow.add_node(\"synthesize_report\", self.synthesize_final_report)\n",
        "        workflow.add_node(\"validate_report\", self.validate_final_report)\n",
        "\n",
        "        # Define workflow edges\n",
        "        workflow.set_entry_point(\"generate_tasks\")\n",
        "        workflow.add_edge(\"generate_tasks\", \"execute_research\")\n",
        "\n",
        "        # Conditional edge for task execution\n",
        "        workflow.add_conditional_edges(\n",
        "            \"execute_research\",\n",
        "            lambda state: \"end\" if not state.tasks else \"execute_research\",\n",
        "            {\n",
        "                \"end\": \"synthesize_report\",\n",
        "                \"execute_research\": \"execute_research\"\n",
        "            }\n",
        "        )\n",
        "\n",
        "        workflow.add_edge(\"synthesize_report\", \"validate_report\")\n",
        "        workflow.add_edge(\"validate_report\", END)\n",
        "\n",
        "        return workflow.compile()\n",
        "\n",
        "async def main():\n",
        "    agent = ResearchLangGraphAgent()\n",
        "    workflow = agent.create_research_workflow()\n",
        "\n",
        "    initial_state = ResearchState(\n",
        "        query=\"What are some recent advancements in Generative AI, and what are its use cases in Healthcare??\"\n",
        "    )\n",
        "\n",
        "    result = await workflow.ainvoke(initial_state)\n",
        "\n",
        "    print(\"\\n=== FINAL RESEARCH REPORT ===\")\n",
        "    print(result[\"final_answer\"])\n",
        "\n",
        "    print(\"\\n=== TASK DETAILS ===\")\n",
        "    for task in result['completed_tasks']:\n",
        "        print(f\"\\nTask {task.task_id} (Priority: {task.priority}):\")\n",
        "        print(task.result)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMrvpm1jMPGp",
        "outputId": "e8d31b95-ef85-4df8-d1a8-7c87de3452e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== FINAL RESEARCH REPORT ===\n",
            "**Comprehensive Report: Recent Advancements in Generative AI and its Applications in Healthcare**\n",
            "\n",
            "**Introduction**\n",
            "\n",
            "Generative AI, a subset of artificial intelligence, has witnessed significant advancements in recent years, particularly in the areas of hyperspectral imagery processing and EEG-based multimodal generation. This report provides an overview of the recent breakthroughs in Generative AI, its potential applications in healthcare, and the implications of its adoption in the healthcare industry.\n",
            "\n",
            "**Recent Advancements in Generative AI**\n",
            "\n",
            "Recent research has led to several key breakthroughs in Generative AI, including:\n",
            "\n",
            "1. **Hyperspectral Imagery Processing:** Deep learning architectures like CNNs, Autoencoders, GANs, and RNNs have shown promise in processing hyperspectral data, with GANs being effective in addressing limited training data and computational constraints.\n",
            "2. **EEG-based Multimodal Generation:** The integration of EEG signals with Generative AI has enabled the generation of images, text, and speech from brain signals, with GANs, VAEs, and Transformer-based models being successful in EEG-to-image and EEG-to-text generation.\n",
            "3. **Advancements in EEG-based Generative AI:** Research has focused on EEG-to-speech synthesis, an emerging multimodal frontier, with key datasets, use cases, challenges, and EEG feature encoding methods being identified to advance neural decoding and assistive technologies.\n",
            "\n",
            "**Trends and Implications**\n",
            "\n",
            "The adoption of Generative AI is becoming increasingly popular, with a growing importance of lightweight models and hardware accelerators to enhance processing efficiency. However, further refinement of deep learning methodologies is needed to address the evolving demands of hyperspectral image processing and EEG-based generative AI.\n",
            "\n",
            "**Potential Applications in Healthcare**\n",
            "\n",
            "Generative AI has several potential applications in healthcare, including:\n",
            "\n",
            "1. **Medical Imaging:** Generating synthetic medical images to augment existing datasets, improve image quality, and aid in image analysis.\n",
            "2. **Disease Diagnosis:** Diagnosing diseases more accurately by generating synthetic patient data, identifying patterns, and predicting patient outcomes.\n",
            "3. **Personalized Medicine:** Aiding in personalized medicine by generating personalized treatment plans, predicting patient responses to different treatments, and identifying potential side effects.\n",
            "4. **Patient Data Augmentation:** Augmenting patient data by generating synthetic data to fill gaps in existing datasets, improving data quality, and enhancing data analysis.\n",
            "\n",
            "**Key Insights and Implications**\n",
            "\n",
            "* Generative AI has the potential to revolutionize healthcare by improving diagnosis accuracy, personalizing treatment plans, and enhancing patient outcomes.\n",
            "* The use of synthetic data can help address data scarcity and quality issues in healthcare, leading to more accurate analysis and decision-making.\n",
            "* However, the development and deployment of Generative AI in healthcare must ensure data privacy, security, and regulatory compliance.\n",
            "\n",
            "**Regulatory and Ethical Considerations**\n",
            "\n",
            "The adoption of Generative AI in healthcare raises significant regulatory and ethical concerns, including:\n",
            "\n",
            "1. **Data Privacy:** Generative AI models require large amounts of sensitive patient data, posing risks of data breaches and unauthorized use.\n",
            "2. **Bias:** AI models can perpetuate existing biases in healthcare data, leading to discriminatory outcomes and exacerbating health disparities.\n",
            "3. **Accountability:** The lack of transparency and explainability in Generative AI models makes it difficult to assign accountability in cases of adverse outcomes or errors.\n",
            "\n",
            "To address these challenges, further research is needed to develop transparent, explainable, and unbiased Generative AI models that prioritize patient privacy and safety. Regulatory frameworks and ethical guidelines must be established to ensure the responsible development and adoption of Generative AI in healthcare.\n",
            "\n",
            "**Conclusion**\n",
            "\n",
            "In conclusion, Generative AI has made significant advancements in recent years, with potential applications in healthcare that can improve diagnosis accuracy, personalize treatment plans, and enhance patient outcomes. However, it is crucial to address the regulatory and ethical concerns associated with its adoption in healthcare, ensuring that patient privacy, safety, and well-being are prioritized.\n",
            "\n",
            "=== TASK DETAILS ===\n",
            "\n",
            "Task T1 (Priority: 1):\n",
            "Here is a concise summary of the research findings on recent advancements in deep learning architectures, focusing on Generative AI, particularly GANs, VAEs, and Transformers:\n",
            "\n",
            "**Key Breakthroughs:**\n",
            "\n",
            "1. **Hyperspectral Imagery Processing:** Deep learning architectures like CNNs, Autoencoders, GANs, and RNNs have shown promise in processing hyperspectral data. GANs, in particular, have been effective in addressing limited training data and computational constraints.\n",
            "2. **EEG-based Multimodal Generation:** Integration of EEG signals with Generative AI has enabled the generation of images, text, and speech from brain signals. GANs, VAEs, and Transformer-based models have been successful in EEG-to-image and EEG-to-text generation.\n",
            "3. **Advancements in EEG-based Generative AI:** Recent research has focused on EEG-to-speech synthesis, an emerging multimodal frontier. Key datasets, use cases, challenges, and EEG feature encoding methods have been identified to advance neural decoding and assistive technologies.\n",
            "\n",
            "**Trends and Implications:**\n",
            "\n",
            "1. **Increased Adoption of Generative AI:** The integration of Generative AI with various domains, such as hyperspectral imagery processing and EEG-based multimodal generation, is becoming increasingly popular.\n",
            "2. **Growing Importance of Lightweight Models:** Lightweight CNN models and 1D CNNs are being explored for onboard processing, highlighting the need for efficient and computationally lightweight models.\n",
            "3. **Hardware Accelerators:** The potential of hardware accelerators, such as FPGAs, is being explored to enhance processing efficiency in deep learning-based applications.\n",
            "4. **Need for Further Exploration:** Despite the advancements, there is a need for further refinement of deep learning methodologies to address the evolving demands of hyperspectral image processing and EEG-based generative AI.\n",
            "\n",
            "**Overall Insights:**\n",
            "\n",
            "The recent research papers highlight the rapid progress in Generative AI, particularly in the areas of hyperspectral imagery processing and EEG-based multimodal generation. The adoption of deep learning architectures like GANs, VAEs, and Transformers is becoming increasingly widespread, and the development of lightweight models and hardware accelerators is crucial for efficient processing. However, further research is needed to address the challenges and limitations in these domains.\n",
            "\n",
            "Task T2 (Priority: 1):\n",
            "I apologize, but it seems that the research data provided is an error message indicating an unauthorized access to a URL. Therefore, I cannot summarize the research findings as there is no actual data to work with.\n",
            "\n",
            "However, I can provide a general overview of the potential use cases of Generative AI in Healthcare, based on existing literature and research:\n",
            "\n",
            "**Potential Use Cases of Generative AI in Healthcare:**\n",
            "\n",
            "1. **Medical Imaging:** Generative AI can be used to generate synthetic medical images, such as X-rays, MRIs, and CT scans, to augment existing datasets, improve image quality, and aid in image analysis.\n",
            "2. **Disease Diagnosis:** Generative AI can help diagnose diseases more accurately by generating synthetic patient data, identifying patterns, and predicting patient outcomes.\n",
            "3. **Personalized Medicine:** Generative AI can aid in personalized medicine by generating personalized treatment plans, predicting patient responses to different treatments, and identifying potential side effects.\n",
            "4. **Patient Data Augmentation:** Generative AI can augment patient data by generating synthetic data to fill gaps in existing datasets, improving data quality, and enhancing data analysis.\n",
            "\n",
            "**Key Insights and Implications:**\n",
            "\n",
            "* Generative AI has the potential to revolutionize healthcare by improving diagnosis accuracy, personalizing treatment plans, and enhancing patient outcomes.\n",
            "* The use of synthetic data can help address data scarcity and quality issues in healthcare, leading to more accurate analysis and decision-making.\n",
            "* However, the development and deployment of Generative AI in healthcare must ensure data privacy, security, and regulatory compliance.\n",
            "\n",
            "Please note that these insights are based on general knowledge and may not reflect the specific research findings, as the provided data is an error message.\n",
            "\n",
            "Task T3 (Priority: 2):\n",
            "I apologize, but it seems that the research data provided is an error message indicating an unauthorized access to a URL. Therefore, I cannot summarize the research findings as there is no actual data to analyze.\n",
            "\n",
            "However, I can provide a general outline of what a summary of successful implementations of Generative AI in Healthcare might look like:\n",
            "\n",
            "**Summary:**\n",
            "\n",
            "The analysis of case studies on successful implementations of Generative AI in Healthcare reveals several best practices, challenges, and lessons learned. Key insights include:\n",
            "\n",
            "* **Best Practices:**\n",
            "\t+ Clear definition of use cases and goals\n",
            "\t+ Collaboration between clinicians, data scientists, and engineers\n",
            "\t+ Robust data curation and annotation\n",
            "\t+ Continuous validation and testing of AI models\n",
            "* **Challenges:**\n",
            "\t+ Ensuring data quality and integrity\n",
            "\t+ Addressing regulatory and ethical concerns\n",
            "\t+ Integrating AI systems with existing healthcare infrastructure\n",
            "\t+ Managing expectations and ensuring transparency\n",
            "* **Lessons Learned:**\n",
            "\t+ The importance of human-AI collaboration in healthcare\n",
            "\t+ The need for ongoing education and training for healthcare professionals\n",
            "\t+ The potential for Generative AI to improve healthcare outcomes and reduce costs\n",
            "\n",
            "**Implications:**\n",
            "\n",
            "The successful implementation of Generative AI in Healthcare has significant implications for improving patient outcomes, reducing healthcare costs, and enhancing the overall efficiency of healthcare systems. However, it is crucial to address the challenges and ensure that AI systems are designed and deployed in a responsible and transparent manner.\n",
            "\n",
            "Please note that this is a hypothetical summary, and actual research findings may vary based on the specific case studies and data analyzed.\n",
            "\n",
            "Task T4 (Priority: 3):\n",
            "I apologize, but it seems that the research data provided is an error message, which doesn't contain any actual research findings. However, I can provide a general summary of the current state of Generative AI in Healthcare from a regulatory and ethical perspective based on existing literature.\n",
            "\n",
            "**Summary:**\n",
            "\n",
            "The adoption of Generative AI in Healthcare is rapidly increasing, but it raises significant regulatory and ethical concerns. Key challenges include:\n",
            "\n",
            "1. **Data Privacy:** Generative AI models require large amounts of sensitive patient data, which poses risks of data breaches and unauthorized use.\n",
            "2. **Bias:** AI models can perpetuate existing biases in healthcare data, leading to discriminatory outcomes and exacerbating health disparities.\n",
            "3. **Accountability:** The lack of transparency and explainability in Generative AI models makes it difficult to assign accountability in cases of adverse outcomes or errors.\n",
            "\n",
            "These challenges can create barriers to adoption, including:\n",
            "\n",
            "1. **Regulatory Uncertainty:** The lack of clear guidelines and regulations for Generative AI in Healthcare hinders widespread adoption.\n",
            "2. **Ethical Concerns:** Healthcare providers and patients may be hesitant to adopt Generative AI due to concerns about data privacy, bias, and accountability.\n",
            "\n",
            "**Implications:**\n",
            "\n",
            "1. **Further Research:** There is a need for further research on developing transparent, explainable, and unbiased Generative AI models that prioritize patient privacy and safety.\n",
            "2. **Regulatory Frameworks:** Governments and regulatory bodies must establish clear guidelines and regulations for the development and deployment of Generative AI in Healthcare.\n",
            "3. **Ethical Guidelines:** Professional organizations and healthcare providers must develop and implement ethical guidelines for the use of Generative AI in Healthcare, ensuring that patient privacy, safety, and well-being are prioritized.\n",
            "\n",
            "By addressing these challenges and implications, we can ensure the responsible development and adoption of Generative AI in Healthcare, ultimately improving patient outcomes and healthcare efficiency.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fkOS3S-MKUfj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}